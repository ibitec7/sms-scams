{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as pd\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet,stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.feature_extraction._tfidf_vectorizer import TfidfTransformer\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import cupy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ibrahim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"~/nltk_data/corpora/stopwords.zip\") == False:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "if os.path.exists(\"~/nltk_data/sentiment/vader_lexicon.zip\") == False:\n",
    "    nltk.download(\"vader_lexicon\")\n",
    "\n",
    "if os.path.exists(\"~/nltk_data/corpora/wordnet.zip\") == False:\n",
    "    nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Spam_SMS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    def __doc__(self):\n",
    "        \"\"\"\n",
    "            Transformer Class to clean and prepare SMS Ham data:\n",
    "\n",
    "            Attributes:\n",
    "            -----------\n",
    "                self.spam_bank (list):\n",
    "\n",
    "                self.ham_bank  (list):\n",
    "\n",
    "                self.spam_urls (list):\n",
    "\n",
    "                self.ham_urls  (list):\n",
    "\n",
    "                self.features  (pd.DataFrame):\n",
    "\n",
    "                self.df  (pd.DataFrame):\n",
    "\n",
    "                self.stopwords (list):\n",
    "\n",
    "                self.lemmatizer (nltk.stem.WordNetLemmatizer):\n",
    "\n",
    "                self.sia (nltk.sentiment.vader.SentimentIntensityAnalyzer):\n",
    "\n",
    "                self.contractions (dict):\n",
    "\n",
    "            Methods:\n",
    "            --------\n",
    "                self.tokenize_words(self, message: str) -> list:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.spam_bank = [l for l in df[df[\"Class\"] == \"spam\"]['Message']]\n",
    "        # self.spam = ' '.join(df[df['Class'] == 'spam'][\"Message\"])\n",
    "        self.ham_bank = [l for l in df[df[\"Class\"] == \"ham\"][\"Message\"]]\n",
    "        self.spam_urls = [url for msg in self.spam_bank for url in re.findall(r'http[s]:\\/\\/[\\S]+', msg)]\n",
    "        self.ham_urls = [url for msg in self.ham_bank for url in re.findall(r'http[s]:\\/\\/[\\S]+', msg)]\n",
    "        self.features = pd.DataFrame({}).to_pandas()\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.df = df.copy()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "        self.contractions = {\n",
    "                                \"can't\": \"cannot\",\n",
    "                                \"won't\": \"will not\",\n",
    "                                \"n't\": \" not\",\n",
    "                                \"'re\": \" are\",\n",
    "                                \"'s\": \" is\",\n",
    "                                \"'d\": \" would\",\n",
    "                                \"'ll\": \" will\",\n",
    "                                \"'ve\": \" have\",\n",
    "                                \"'m\": \" am\",\n",
    "                            }\n",
    "\n",
    "    def tokenize_words(self, message: str) -> list:\n",
    "        tokenizer = RegexpTokenizer(r\"[^\\s.,?!]+\")\n",
    "        tokens = tokenizer.tokenize(message)\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def expand_contractions(self, text, contractions_dict):\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), \n",
    "                                        flags=re.IGNORECASE | re.DOTALL)\n",
    "        def replace(match):\n",
    "            return contractions_dict[match.group(0).lower()]\n",
    "        \n",
    "        return contractions_pattern.sub(replace, text)\n",
    "    \n",
    "    def clean_msg(self):\n",
    "        self.features['clean_msg'] = self.df['Message'].str.lower()\n",
    "        self.features[\"target\"] = self.df[\"Class\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: self.expand_contractions(x, self.contractions))\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].str.replace(r'http[s]:\\/\\/[\\S]+', '<url>', regex=True)\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "        \n",
    "        sym_spell = SymSpell(max_dictionary_edit_distance=4, prefix_length=7)\n",
    "        dictionary = \"frequency_dictionary_en_82_765.txt\"\n",
    "        sym_spell.load_dictionary(dictionary,term_index=0,count_index=1)\n",
    "\n",
    "        def correct(msg: str) -> str:\n",
    "            suggestions = []\n",
    "            for word in msg.split():\n",
    "                suggestion = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=3)\n",
    "                if suggestion:\n",
    "                    suggestions.append(suggestion[0].term)\n",
    "                else:\n",
    "                    suggestions.append(word)\n",
    "\n",
    "            return \" \".join(suggestions)\n",
    "        \n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: correct(x))\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: \" \".join([word for word in x.split() if word not in self.stopwords]))\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: \" \".join([self.lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].str.replace(r'\\d+', '<num>', regex=True)\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].str.strip()\n",
    "        self.features['clean_msg'] = self.features['clean_msg'].apply(lambda x: \" \".join([word for word in x.split() if len(word) > 2]))\n",
    "\n",
    "        return self.features\n",
    "    \n",
    "    def ngrams(self):\n",
    "        spam_blob = self.features[self.features[\"target\"]==1][\"clean_msg\"].str.cat()\n",
    "        ham_blob = self.features[self.features[\"target\"]==0][\"clean_msg\"].str.cat()\n",
    "\n",
    "        spam_tokens = self.tokenize_words(spam_blob)\n",
    "        ham_tokens = self.tokenize_words(ham_blob)\n",
    "\n",
    "        spam_bigrams = Counter(list(ngrams(spam_tokens,2)))\n",
    "        spam_trigrams = Counter(list(ngrams(spam_tokens,3)))\n",
    "\n",
    "        ham_bigrams = Counter(list(ngrams(ham_tokens,2)))\n",
    "        ham_trigrams = Counter(list(ngrams(ham_tokens,3)))\n",
    "\n",
    "        return spam_bigrams, spam_trigrams, ham_bigrams, ham_trigrams\n",
    "\n",
    "    \n",
    "    def feature_eng(self):\n",
    "        self.features['char_count'] = self.df['Message'].apply(len)\n",
    "        self.features['word_count'] = self.features['clean_msg'].apply(lambda msg: len(self.tokenize_words(msg)))\n",
    "        self.features['digit_count'] = self.df['Message'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "        self.features['question_count'] = self.df['Message'].apply(lambda x: x.count('?'))\n",
    "        self.features['exclamation_count'] = self.df['Message'].apply(lambda x: x.count('!'))\n",
    "        self.features['dollar_count'] = self.df['Message'].apply(lambda x: x.count('$') + x.count('€') + x.count('£'))\n",
    "        self.features['cap_ratio'] = self.df['Message'].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x))\n",
    "        self.features['unique_words'] = self.features['clean_msg'].apply(lambda x: len(set(x.split())))\n",
    "        self.features['repitition_factor'] = self.features['word_count'].astype(float) / self.features['unique_words'].astype(float)\n",
    "        self.features['sentiment'] = self.features['clean_msg'].apply(lambda x: self.sia.polarity_scores(x)['compound'])\n",
    "\n",
    "        self.features.to_csv(\"prepared_data.csv\")\n",
    "\n",
    "        return self.features\n",
    "    \n",
    "    def word_count(self, word_bank: list) -> dict:\n",
    "        pattern = r\"[^\\s./!?]+\"\n",
    "        tokenizer = RegexpTokenizer(pattern)\n",
    "        counts = list()\n",
    "        for msg in word_bank:\n",
    "            words_count = dict()\n",
    "            words = tokenizer.tokenize(msg)\n",
    "            for word in words:\n",
    "                if words_count.keys().__contains__(word) == False:\n",
    "                    words_count[word] = words.count(word)\n",
    "                else:\n",
    "                    continue\n",
    "            counts.append(words_count)\n",
    "\n",
    "        return counts\n",
    "    \n",
    "    def cap_count(self, tokens: list) -> int:\n",
    "        count = int(0)\n",
    "        for word in tokens:\n",
    "            if word.isupper() == True:\n",
    "                count += 1\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point crazy available bug great world buffet c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lar joking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win cup final tit list ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dun say early hor already say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah think life around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>time tried contact £&lt;num&gt; pound prize claim ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>going esplanade home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>pity mood sony suggestion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>guy bitching acted like would interested buyin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>roll true name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_msg  target\n",
       "0     point crazy available bug great world buffet c...       0\n",
       "1                                            lar joking       0\n",
       "2     free entry wkly comp win cup final tit list ma...       1\n",
       "3                         dun say early hor already say       0\n",
       "4                          nah think life around though       0\n",
       "...                                                 ...     ...\n",
       "5569  time tried contact £<num> pound prize claim ea...       1\n",
       "5570                               going esplanade home       0\n",
       "5571                          pity mood sony suggestion       0\n",
       "5572  guy bitching acted like would interested buyin...       0\n",
       "5573                                     roll true name       0\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Transformer(df.to_pandas())\n",
    "f.clean_msg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_bigrams, spam_trigrams, ham_bigrams, ham_trigrams = f.ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spam_bigrams.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_spam_bigrams = pd.DataFrame({\"bigram\": spam_bigrams.keys(), \"count\": spam_bigrams.values()})\n",
    "df_spam_bigrams.to_csv(\"spam_bigrams.csv\")\n",
    "df_spam_trigrams = pd.DataFrame({\"trigram\": spam_trigrams.keys(), \"count\": spam_trigrams.values()})\n",
    "df_spam_trigrams.to_csv(\"spam_trigrams.csv\")\n",
    "df_ham_bigrams = pd.DataFrame({\"bigrams\": ham_bigrams.keys(), \"count\": ham_bigrams.values()})\n",
    "df_ham_bigrams.to_csv(\"ham_bigrams.csv\")\n",
    "df_ham_trigrams = pd.DataFrame({\"trigrams\": ham_trigrams.keys(), \"count\": ham_trigrams.values()})\n",
    "df_ham_trigrams.to_csv(\"ham_trigrams.csv\")\n",
    "\n",
    "import cudf as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(free, entry)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(entry, wkly)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(wkly, comp)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(comp, win)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(win, cup)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>(name, house)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>(house, postcodetime)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>(postcodetime, tried)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>(£&lt;num&gt;, pound)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>(minute, btnationalrate)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5430 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bigram  count\n",
       "0                (free, entry)      8\n",
       "1                (entry, wkly)      5\n",
       "2                 (wkly, comp)      4\n",
       "3                  (comp, win)      2\n",
       "4                   (win, cup)      2\n",
       "...                        ...    ...\n",
       "5425             (name, house)      1\n",
       "5426     (house, postcodetime)      1\n",
       "5427     (postcodetime, tried)      1\n",
       "5428           (£<num>, pound)      1\n",
       "5429  (minute, btnationalrate)      1\n",
       "\n",
       "[5430 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_msg</th>\n",
       "      <th>target</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>dollar_count</th>\n",
       "      <th>cap_ratio</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>repitition_factor</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point crazy available bug great world buffet c...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lar joking</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win cup final tit list ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>17</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>0.7964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dun say early hor already say</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>5</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah think life around though</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>time tried contact £&lt;num&gt; pound prize claim ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>going esplanade home</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>pity mood sony suggestion</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>guy bitching acted like would interested buyin...</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>roll true name</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_msg  target  char_count  \\\n",
       "0     point crazy available bug great world buffet c...       0         111   \n",
       "1                                            lar joking       0          29   \n",
       "2     free entry wkly comp win cup final tit list ma...       1         155   \n",
       "3                         dun say early hor already say       0          49   \n",
       "4                          nah think life around though       0          61   \n",
       "...                                                 ...     ...         ...   \n",
       "5569  time tried contact £<num> pound prize claim ea...       1         160   \n",
       "5570                               going esplanade home       0          36   \n",
       "5571                          pity mood sony suggestion       0          57   \n",
       "5572  guy bitching acted like would interested buyin...       0         125   \n",
       "5573                                     roll true name       0          26   \n",
       "\n",
       "      word_count  digit_count  question_count  exclamation_count  \\\n",
       "0             10            0               0                  0   \n",
       "1              2            0               0                  0   \n",
       "2             20           25               0                  0   \n",
       "3              6            0               0                  0   \n",
       "4              5            0               0                  0   \n",
       "...          ...          ...             ...                ...   \n",
       "5569          13           21               0                  1   \n",
       "5570           3            0               1                  0   \n",
       "5571           4            0               1                  0   \n",
       "5572          13            0               0                  0   \n",
       "5573           3            0               0                  0   \n",
       "\n",
       "      dollar_count  cap_ratio  unique_words  repitition_factor  sentiment  \n",
       "0                0   0.027027            10           1.000000     0.4019  \n",
       "1                0   0.068966             2           1.000000     0.2263  \n",
       "2                0   0.064516            17           1.176471     0.7964  \n",
       "3                0   0.040816             5           1.200000     0.0000  \n",
       "4                0   0.032787             5           1.000000    -0.1027  \n",
       "...            ...        ...           ...                ...        ...  \n",
       "5569             1   0.056250            13           1.000000     0.7351  \n",
       "5570             0   0.027778             3           1.000000     0.0000  \n",
       "5571             0   0.035088             4           1.000000    -0.2960  \n",
       "5572             0   0.016000            13           1.000000     0.7506  \n",
       "5573             0   0.076923             3           1.000000     0.4215  \n",
       "\n",
       "[5574 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.feature_eng()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
